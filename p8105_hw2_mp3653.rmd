---
title: "p8105_hw2_mp3653"
author: "Matthew Perrotta"
date: "October 4, 2018"
output: github_document
---

### Load Necessary Package(s)
```{r}
library(tidyverse)
library(readxl)
library(p8105.datasets)
```

# Problem 1
### Import Data: NYC Transit data
```{r data import and cleaning}
NYC_transit = read.csv(file = './data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv') %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

### The Dataset
The NYC_transit dataset contains 19 variables describing subway stations and where their entrances are located, what subway lines they service, and accessibility information.

After importing the dataset, I used a series of pipes to chain together multiple functions. Using the `clean_names()` function in the janitor package, I reformatted the original variable names, replacing '.' with '_' and all uppercase letters with lowercase letters. Following this, I selected the variables I wanted to keep using the `select()` function. Finally, using the `mutate()` and `recode()` functions I changed the variable 'entry' data type to logical.

The NYC_transit dataset is `r nrow(NYC_transit)` rows by `r ncol(NYC_transit)` columns.

This dataset is not tidy. While easy to read, the variables route1 through route11 can be condensed down to a single column, reformatting the dataset from wide to long.

There are `r nrow(distinct(NYC_transit, line, station_name))` distinct stations in the NYC subway system. The number of these stations that are ADA compliant are `r nrow(filter(distinct(NYC_transit, line, station_name, ada), ada == TRUE))`. The proportion of station entrances/exits without vending that allow entrance is `r nrow(filter(NYC_transit, vending == 'NO', entry == TRUE))/nrow(filter(NYC_transit, vending == 'NO'))`.

Reformatting data so that it is more tidy:
```{r tidy up dataset}
NYC_transit_tidy = gather(NYC_transit, key = route_number, value = route_name, route1:route11)
```
The number of distinct stations that serve the A train are `r nrow(filter(distinct(NYC_transit_tidy, line, station_name, route_name), route_name == "A"))`. The number of these stations that are ADA compliant are `r nrow(filter(filter(distinct(NYC_transit_tidy, line, station_name, route_name, ada), route_name == "A"), ada == TRUE))`

# Problem 2
### Import Data: Mr. Trash Wheel data and precipitation data
```{r data import and cleaning for problem 2}
trash = read_excel('./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx', 'Mr. Trash Wheel', 
                   range = "A2:N338") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = round(sports_balls)) %>% 
  mutate(sports_balls = as.integer(sports_balls))

precp_2017 = read_excel('./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx', '2017 Precipitation',
                        range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = 2017) %>% 
  rename(total_precipitation = total)

precp_2016 = read_excel('./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx', '2016 Precipitation',
                        range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = 2016) %>%   
  rename(total_precipitation = total)
```

### Combine precipitation datasets
```{r using rbind to combine datasets}
precp_data = rbind(
  mutate(
    precp_2016, month = month.name), 
  mutate(
    precp_2017, month = month.name))
```

### The Dataset
The dataset `trash` contains `r nrow(trash)` observations. Of the `r ncol(trash)` variables, `weight_tons` and `volume_cubic_yards` are key in understanding the amount of trash collected in the harbor and to guage the effectiveness of the trash collecting methods.

The dataset `precp_data` contains `nrow(precp_data)` observations. There are only `r ncol(precp_data)` variables in the dataset, however, `total_precipitation` is key in understanding rainfall per month in the harbor.

In 2017, the total precipitation was `r sum(filter(precp_data, year == 2017)$total_precipitation)`inches. The median number of sports balls collected in 2016 was `r median(filter(trash, year == 2016)$sports_balls)`. 

# Problem 3
### Import Data: 
```{r}
brfss = p8105.datasets::brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  filter(topic == 'Overall Health') %>% 
  select(-class, -topic, -question, -sample_size, -confidence_limit_low:-geo_location) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(prop_excellent_vgood = (excellent + very_good)/(excellent + very_good + good + fair + poor))
```

There are `r nrow(distinct(brfss, state, county))` unique locations in the dataset. 

There are `r nrow(distinct(brfss, state))` states reported in the dateset, indicating that all of them are accounted for (including the District of Columbia). 

```{r}
sort(table(brfss$state))
```

The state that appears the most is New Jersey (NJ)

In 2002, the median of the "Excellent" response variable was `r median(filter(brfss, year == 2002)$excellent, na.rm = TRUE)`.

### histogram
```{r create histogram for excellent responses in 2002}
brfss %>% 
  filter(year == 2002) %>% 
  ggplot(aes(x = excellent)) +
  geom_histogram()
```


### scatterplot
```{r create scatterplot}
brfss %>% 
  filter(county %in% c("NY - New York County", "NY - Queens County")) %>% 
  filter(year >= 2002, year <= 2010) %>% 
  ggplot(aes(x = year, y = prop_excellent_vgood)) +
  geom_point()
```

