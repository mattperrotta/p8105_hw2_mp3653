p8105\_hw2\_mp3653
================
Matthew Perrotta
October 4, 2018

### Load Necessary Package(s)

``` r
library(tidyverse)
```

    ## -- Attaching packages --------------------------------------------------------------------------- tidyverse 1.2.1 --

    ## v ggplot2 3.0.0     v purrr   0.2.5
    ## v tibble  1.4.2     v dplyr   0.7.6
    ## v tidyr   0.8.1     v stringr 1.3.1
    ## v readr   1.1.1     v forcats 0.3.0

    ## -- Conflicts ------------------------------------------------------------------------------ tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
library(p8105.datasets)
```

Problem 1
=========

### Import Data: NYC Transit data

``` r
NYC_transit = read.csv(file = './data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv') %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

### The Dataset

The NYC\_transit dataset contains 19 variables describing subway stations and where their entrances are located, what subway lines they service, and accessibility information.

After importing the dataset, I used a series of pipes to chain together multiple functions. Using the `clean_names()` function in the janitor package, I reformatted the original variable names, replacing '.' with '\_' and all uppercase letters with lowercase letters. Following this, I selected the variables I wanted to keep using the `select()` function. Finally, using the `mutate()` and `recode()` functions I changed the variable 'entry' data type to logical.

The NYC\_transit dataset is 1868 rows by 19 columns.

This dataset is not tidy. While easy to read, the variables route1 through route11 can be condensed down to a single column, reformatting the dataset from wide to long.

There are 465 distinct stations in the NYC subway system. The number of these stations that are ADA compliant are 84. The proportion of station entrances/exits without vending that allow entrance is 0.3770492.

Reformatting data so that it is more tidy:

``` r
NYC_transit_tidy = gather(NYC_transit, key = route_number, value = route_name, route1:route11)
```

    ## Warning: attributes are not identical across measure variables;
    ## they will be dropped

The number of distinct stations that serve the A train are 60. The number of these stations that are ADA compliant are 17

Problem 2
=========

### Import Data: Mr. Trash Wheel data and precipitation data

``` r
trash = read_excel('./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx', 'Mr. Trash Wheel', 
                   range = "A2:N338") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = round(sports_balls)) %>% 
  mutate(sports_balls = as.integer(sports_balls))

precp_2017 = read_excel('./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx', '2017 Precipitation',
                        range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = 2017) %>% 
  rename(total_precipitation = total)

precp_2016 = read_excel('./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx', '2016 Precipitation',
                        range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = 2016) %>%   
  rename(total_precipitation = total)
```

### Combine precipitation datasets

``` r
precp_data = rbind(
  mutate(
    precp_2016, month = month.name), 
  mutate(
    precp_2017, month = month.name))
```

### The Dataset

The dataset `trash` contains 285 observations. Of the 14 variables, `weight_tons` and `volume_cubic_yards` are key in understanding the amount of trash collected in the harbor and to guage the effectiveness of the trash collecting methods.

The dataset `precp_data` contains `nrow(precp_data)` observations. There are only 3 variables in the dataset, however, `total_precipitation` is key in understanding rainfall per month in the harbor.

In 2017, the total precipitation was 32.93inches. The median number of sports balls collected in 2016 was 26.

Problem 3
=========

### Import Data:

``` r
brfss = p8105.datasets::brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  filter(topic == 'Overall Health') %>% 
  select(-class, -topic, -question, -sample_size, -confidence_limit_low:-geo_location) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(prop_excellent_vgood = (excellent + very_good)/(excellent + very_good + good + fair + poor))
```

There are 404 unique locations in the dataset.

There are 51 states reported in the dateset, indicating that all of them are accounted for (including the District of Columbia).

``` r
sort(table(brfss$state))
```

    ## 
    ##  VA  DC  KY  WI  WV  AK  IA  AL  MT  ND  NV  SD  AR  IN  WY  MS  IL  MO 
    ##   4   9   9   9   9  11  14  18  18  18  18  18  21  21  22  23  25  25 
    ##  TN  DE  GA  HI  ME  AZ  ID  MN  OR  MI  KS  RI  OK  NM  LA  CT  NH  VT 
    ##  26  27  27  31  31  32  32  33  33  34  38  38  40  43  45  47  48  48 
    ##  UT  CA  NE  CO  OH  PA  SC  NY  TX  MA  MD  WA  NC  FL  NJ 
    ##  50  52  53  59  59  59  63  65  71  79  90  97 115 122 146

The state that appears the most is New Jersey (NJ)

In 2002, the median of the "Excellent" response variable was 23.6.

### histogram

``` r
brfss %>% 
  filter(year == 2002) %>% 
  ggplot(aes(x = excellent)) +
  geom_histogram()
```

    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.

    ## Warning: Removed 2 rows containing non-finite values (stat_bin).

![](p8105_hw2_mp3653_files/figure-markdown_github/create%20histogram%20for%20excellent%20responses%20in%202002-1.png)

### scatterplot

``` r
brfss %>% 
  filter(county %in% c("NY - New York County", "NY - Queens County")) %>% 
  filter(year >= 2002, year <= 2010) %>% 
  ggplot(aes(x = year, y = prop_excellent_vgood)) +
  geom_point()
```

![](p8105_hw2_mp3653_files/figure-markdown_github/create%20scatterplot-1.png)
